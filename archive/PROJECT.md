# Project Atom

> 인간 움직임의 디지털 트윈을 만든다.
> 복싱에서 시작해, 방대한 데이터와 기술력으로 인간 동작 이해의 생태계를 구축한다.

---

## 비전

Palantir가 국방/기업의 운영을 디지털 트윈화하여 의사결정을 장악했듯, Project Atom은 **인간의 신체 움직임**을 디지털 트윈화하여 훈련, 분석, 예측의 생태계를 만든다.

```
현실 (나의 움직임)
    → 디지털 트윈 (분석 / 시뮬레이션 / 예측)
    → 현실에 피드백 (코칭)
    → Physical AI로 현실에 재투입 (로봇)
```

---

## 전략: 두 개의 트랙

### 트랙 1 (무료) — 데이터 엔진

사용자에게 **충분히 쓸만한 앱**을 무료로 준다. 대신 데이터를 얻는다.

```
사용자가 얻는 것:
  공격+방어가 섞인 AI 섀도우 스파링 (리얼 스틸의 아톰처럼)
  세션 후 분석 리포트 (정량 + 자체 코칭 모델 피드백)
  기본 디지털 트윈 (약점 지도, 다음 세션 추천)
  기본 스파링 분석 (펀치 카운트, 기본 통계)

우리가 얻는 것:
  자동 라벨링 데이터 (지시 타임스탬프 = 라벨)
  수십만 명의 움직임 디지털 트윈
```

트랙 1이 해자인 이유: 단순 패드워크(공격만)는 타이머+음성으로 복제 가능하다. **공격+방어 섀도우 스파링은 동작 인식 없이 불가능하다.** 방어 반응 속도, 공방 전환, 어떤 공격에 약한지 — 이 데이터는 동작 인식이 있어야만 나온다. 그리고 3개월 쓴 사용자의 트윈(약점 지도, 성장 곡선)은 다른 앱에 없다.

### 트랙 2 (프리미엄) — 수익 엔진

유료 근거는 **비용이 아니라 경험과 데이터의 깊이.** 비용은 내려가지만, 경험 프리미엄과 데이터 프리미엄은 시간이 갈수록 올라간다.

| 기능 | 유료 근거 |
|------|----------|
| **실시간 카메라 피드백** | 경험 프리미엄. "끝나고 복기" vs "하는 중에 교정" = 코치가 옆에 있는 것. 온디바이스 추론 개발 난이도도 높음. |
| **VLM 프리미엄 코칭** | 품질 프리미엄. 자체 모델("팔꿈치 떨어졌습니다") vs VLM("3라운드 이후 피로로 어깨 회전이 줄어 파워가 빠지고 있습니다. 1~2라운드 잽 위주 운용 후 3라운드부터 파워샷을 쓰는 전략을 연습하세요") |
| **심층 디지털 트윈** | 데이터 프리미엄. 전체 히스토리 기반 성장 예측, 백분위, 상황별 약점 맵. 축적 데이터 없이 복제 불가. |
| **트윈 시뮬레이션** | 데이터 프리미엄. 프로 파이터 프로필 DB + 매치 시뮬레이션. |
| **고급 스파링 분석** | 데이터 프리미엄. 상호작용 분석, 시계열 비교 ("3개월 전 vs 지금"). |
| **코치/체육관 도구** | B2B 프리미엄. 멀티유저 대시보드. |

### VLM 비용 전략: 부트스트래핑 → 자체 모델

VLM은 영원한 비용 센터가 아니다. 자체 코칭 모델을 키우는 부트스트래핑 도구다.

```
Phase 2 초기 (사용자 1,000명):
  VLM으로 코칭 피드백 생성. 비용 감당 가능 ($750~2,250/주).
  동시에 [영상 클립 + 키포인트 + VLM 코칭 텍스트] 페어를 축적.

Phase 3 (사용자 증가):
  축적된 페어로 자체 경량 코칭 모델 파인튜닝.
  흔한 패턴 ("팔꿈치 떨어짐", "가드 내려감")은 자체 모델이 처리.
  VLM은 복잡한 케이스만 담당. 호출량 70~80% 감소.

Phase 4+ (사용자 대량):
  자체 모델이 대부분 커버. VLM은 새 패턴 발견 / 모델 개선용만.
  호출량 90%+ 감소.
```

이것도 플라이휠이다:
```
VLM이 코칭 생성 → (클립, 코칭) 페어 축적
  → 자체 모델 학습 → VLM 의존도 감소 → 비용 하락
  → 무료 사용자에게 더 많이 제공 → 더 많은 데이터
  → 자체 모델 개선 → ...
```

자체 코칭 모델이 성장하면 무료에서 제공하는 코칭 품질도 올라간다. 무료 코칭("팔꿈치 떨어졌습니다")과 유료 VLM 코칭("3라운드 이후 피로 패턴 분석 + 전략 제안")의 **질적 차이**가 유료 전환의 근거가 된다.

### 이중 플라이휠

```
트랙 1: 무료 사용자 → 자동 라벨링 데이터 → 모델 개선 → 더 좋은 앱 → 더 많은 사용자
트랙 2: 트랙 1 데이터 → 프리미엄 모델 → 수익 → 재투자 → 더 좋은 모델

연결: 트랙 1의 데이터가 트랙 2의 모델을 만든다.
      트랙 2의 수익이 트랙 1의 개선에 재투자된다.
      VLM 코칭 데이터가 자체 모델을 키운다.
```

---

## 듀얼 트랙 분석 아키텍처

MediaPipe + ST-GCN만으로는 한계가 명확하다. 두 트랙이 각각의 강점을 담당한다.

```
영상 ─┬─→ 트랙 1 (정량): MediaPipe → ST-GCN
      │     "뭘 했는가, 얼마나 빨리 했는가"
      │     동작 분류, 타이밍, 반응 속도, 가드 모니터링
      │     ✅ 할 수 있는 것: 동작 분류, 시퀀스, 타이밍
      │     ❌ 못하는 것: 3D 궤적, 미세 회전, 하체 디테일
      │
      └─→ 트랙 2 (정성): 영상 클립 → VLM
            "얼마나 잘 했는가, 어떻게 고쳐야 하는가"
            폼 교정, 전술 조언, 자연어 코칭
            "크로스 시 뒷발 피벗이 부족합니다"
            "슬립 시 무릎 굴곡이 부족합니다"

결합 예시:
  정량: "덕 반응 0.55초. 목표 대비 0.1초 느림."
  정성: "덕 시 무릎 굴곡이 부족합니다. 하체를 더 쓰면 복귀가 빨라집니다."
```

지시-수행-검증 구조가 두 트랙 모두를 강화한다. AI가 "크로스"를 지시했으므로, 트랙 1은 탐색 공간이 좁아져 정확도가 올라가고, 트랙 2는 VLM에 "이 구간은 크로스를 지시한 구간"이라는 컨텍스트를 줄 수 있다.

---

## Phase 로드맵

### Phase 1: 동작 이해 엔진

> 모든 것의 기반. 영상에서 복싱 동작을 이해하는 시퀀스 모델.

**목표:** 5개 동작 분류 ≥ 80%, 콤보 감지, <500ms 지연

```
데이터 촬영 (5→15→45영상)
  → 키포인트 추출 (MediaPipe) + 시각적 검증
  → 전처리 → Parquet
  → RF (sanity check) → LSTM → ST-GCN
  → 실시간 추론 데모
```

아키텍처:
```
영상 (30fps)
  → MediaPipe (33kp) → 스무딩 → 9kp 선택 → 힙 정규화
  → 슬라이딩 윈도우 (30f, stride 5)
  → ST-GCN → 동작 + 신뢰도
```

---

### Phase 2: 코칭 앱 MVP — 트랙 1 출시

> 무료로 풀어서 데이터 플라이휠을 가동한다. **트랙 1만으로 충분히 쓸만한 앱.**

**목표:** 앱스토어 출시. 사용자가 혼자 섀도우 복싱하는 것보다 압도적으로 유용.

**① 오디오 섀도우 스파링**
```
사용자 경험:
  에어팟으로 AI의 공격/방어 지시 → 섀도우 복싱 + 녹화

  AI: "잽-크로스!"     → 사용자 공격
  AI: "슬립!"         → 사용자 방어 (가상 상대의 훅 회피)
  AI: "카운터 잽!"     → 사용자 반격

아키텍처:
  세션 엔진 (서버)
    스크립트 생성: [{ t: 0.0, type: "attack", cmd: "잽-크로스" },
                   { t: 3.2, type: "defend", cmd: "슬립" }, ...]
    난이도: 지시 간격 / 공방 비율 / 콤보 길이 조절
  오디오 엔진 (클라이언트)
    사전 녹음 음성, 스크립트 타이밍에 맞춰 재생
  녹화 (클라이언트)
    720p 30fps, 세션 스크립트와 시작 타임스탬프 동기화

기술: 규칙 엔진, 사전 녹음 / Edge-TTS, React Native, GCS
```

**② 세션 후 분석 (정량 + 자체 코칭 모델)**
```
사용자 경험:
  녹화 업로드 → 세션 리포트

  리포트 예시:
    0:05  잽-크로스        ✅ 크로스 속도 양호
    0:08  슬립 (상대 훅)    ✅ 반응 0.3초
    0:15  잽-잽-훅         ⚠️ "훅에서 팔꿈치가 떨어졌습니다. 가드 높이를 유지하세요."
    0:19  덕 (상대 크로스)   ❌ 반응 0.6초 — "덕 반응이 느립니다."

    공격: 완수율 85%. 4연타 이후 누락 경향.
    방어: 슬립 0.3초 ✅, 덕 0.55초 ⚠️
    전환: 공→방 0.35초, 카운터 0.25초
    추천: 덕 반응 집중 + 덕 후 카운터 드릴

아키텍처:
  영상 → MediaPipe → ST-GCN → 동작 시퀀스
  검증 엔진: 세션 스크립트 ↔ 동작 시퀀스 시간 정렬
    지시별 판정 (✅ ⚠️ ❌), 메트릭 계산
  자체 코칭 모델: 흔한 교정 패턴 피드백
    (초기: 규칙 기반. 이후: VLM 코칭 데이터로 파인튜닝한 경량 모델)
  리포트 생성: 공격/방어/전환 요약 + 코칭 + 다음 세션 추천

기술: PyTorch (ST-GCN), FastAPI, GCP Cloud Run
```

**③ 디지털 트윈 기본**
```
사용자 경험:
  세션이 쌓일수록 나의 약점 지도와 성장 곡선이 보인다.
  다음 세션이 내 약점에 맞게 자동 구성된다.

아키텍처:
  세션 리포트 → 동작별 통계 갱신 (누적, 시계열)
  약점 자동 감지 ("덕 반응 > 0.45초" → 플래그)
  성장 곡선 (주간/월간 변화)
  적응형 피드백 → ①의 스크립트 생성기에 주입

기술: PostgreSQL + TimescaleDB, pandas/scipy
```

**이 Phase에서 시작되는 것:**
- 자동 라벨링 데이터 축적 (사용자 100명 × 30일 = 월 27만 개)
- 사용자별 디지털 트윈 구축
- 전환 비용 형성 (3개월 사용 시 이탈 어려움)

---

### Phase 3: 프리미엄 출시 — 트랙 2로 수익화

> 트랙 1이 축적한 데이터와 더 좋은 모델로 깊은 분석 제공. 수익화 시작. VLM 코칭 데이터로 자체 모델 부트스트래핑 병행.

**④ 실시간 카메라 피드백** (경험 프리미엄)
```
"끝나고 복기" vs "하는 중에 교정" — 코치가 옆에 있는 것의 차이.

아키텍처:
  카메라 → MediaPipe (온디바이스) → TFLite ST-GCN (INT8 양자화)
  → 실시간 UI 오버레이: "✅ 잽" "⚠️ 가드↓" "0.3초"

기술: TFLite / ONNX Runtime, INT8 양자화
개발 난이도: 높음 (모델 변환, 디바이스별 최적화, 배터리/발열 관리)
```

**⑤ VLM 프리미엄 코칭** (품질 프리미엄)
```
자체 모델이 못 잡는 미묘한 분석. 전술 수준의 코칭.

  무료 (자체 모델): "팔꿈치가 떨어졌습니다. 가드를 유지하세요."
  유료 (VLM):      "3라운드 이후 피로로 크로스의 어깨 회전이 줄어들고 있습니다.
                    1~2라운드는 잽 위주로 운용하고 3라운드부터 파워샷을
                    쓰는 전략을 연습하세요."

아키텍처:
  ②에서 핵심 구간 클립 추출 (FFmpeg, 3~5초)
  → VLM API + 컨텍스트 프롬프트
  → 정량(②) + 정성(⑤) 통합 리포트

  동시에: [클립 + VLM 코칭] 페어를 축적 → 자체 모델 학습 데이터

기술: GPT-4o / Gemini Pro Vision, FFmpeg
비용 관리: 핵심 구간만 분석. 자체 모델 성장 시 VLM 호출 90%+ 감소.
```

**⑤-1 심층 디지털 트윈** (데이터 프리미엄)
```
무료 트윈: 최근 약점, 다음 세션 추천
유료 트윈: 전체 히스토리 기반 심층 분석

  - 장기 성장 곡선 (3개월, 6개월, 1년 추이)
  - 상황별 약점 맵 ("피로 시 덕 반응 0.2초 느려짐")
  - 성장 예측 ("현재 추세로 3주 후 덕 0.4초 도달 예상")
  - 다른 사용자 대비 내 위치 (백분위)

이건 축적된 데이터 없이 복제 불가.
```

**⑥ 스파링 영상 분석** (기본 무료 / 고급 유료)
```
기본 (무료): 펀치 카운트, 유형 분포, 라운드별 활동량
고급 (유료): 상호작용 분석, 시계열 비교

아키텍처:
  영상 → 다중 인물 포즈 추출 (MMPose) + 추적 (ByteTrack)
  → 인물별 ST-GCN 동작 분류
  → 기본: 펀치 통계, 활동량
  → 고급: 상호작용 분석
      A의 잽(1.2초) → B의 슬립(1.4초) → 반응 0.2초
      A의 훅(3.5초) → B 반응 없음 → 피격
  → 시계열 비교: "3개월 전 스파링 vs 지금, 뭐가 달라졌나"

기술: MMPose, ByteTrack, GPU 인스턴스
```

---

### Phase 4: 트윈 시뮬레이션 + B2B

> 디지털 트윈의 진짜 가치. 현실에서 불가능한 것을 디지털에서 한다.

**⑦ 트윈 시뮬레이션**
```
"타이슨 스타일과 스파링해줘"

아키텍처:
  경기 영상 → ⑥ 파이프라인 → 파이터 프로필
    (선호 콤보, 공격/방어 패턴, 상황별 반응 분포)
  프로필 + 사용자 트윈 → 맞춤 세션 생성
    타이슨: 왼쪽 훅 빈도 ↑ → 왼쪽 훅 방어 비중 ↑

  매치 시뮬레이션 (디지털):
    나의 트윈 vs 타이슨 트윈 → 통계적 매칭
    "현재 덕 반응으로 훅 35% 회피. 0.1초 개선 시 60%."

기술: ⑥ 재사용, 확률 모델 → RL
```

**⑧ 코치/체육관 도구 (B2B)**
```
코치가 제자들의 트윈을 한 화면에서 관리.

  "이번 주 A는 덕 반응이 퇴보, B는 카운터가 개선"
  제자별 약점 기반 드릴 일괄 구성
  체육관 단위 구독 → 코치 1명이 제자 전원에게 앱 추천 → 바이럴

개인 앱으로는 제공할 수 없는 멀티유저 데이터 레이어.
```

---

### Phase 5: 도메인 확장 — 디지털 트윈 플랫폼

> 복싱을 넘어선다. "지시-수행-검증"은 도메인 독립적이다.

| 도메인 | 지시 | 수행 | 검증 |
|--------|------|------|------|
| 복싱 | 잽-크로스-슬립 | 공방 수행 | 동작, 타이밍, 반응 |
| MMA/태권도 | 앞차기-돌려차기 | 품새 수행 | 자세, 각도, 밸런스 |
| 댄스 | 8카운트 안무 | 안무 수행 | 타이밍, 동선 |
| 재활 | 무릎 굴곡 15회 | 운동 수행 | ROM, 대칭성 |

모든 도메인에서 같은 구조가 동작하고, 같은 자동 라벨링이 일어나고, 같은 디지털 트윈이 구축된다. 도메인이 추가될수록 동작 이해 모델이 범용화되고, 데이터 해자가 두꺼워진다.

```
Phase 5 아키텍처:
  도메인 앱 (복싱 / MMA / 댄스 / 재활)
      ↓
  코어 플랫폼 (세션 엔진, 검증 엔진, 트윈 엔진)
      ↓
  자동 라벨링 데이터 플라이휠
      ↓
  범용 인간 동작 이해 모델
```

---

### Phase 6: Physical AI

> 디지털 트윈 데이터를 현실 세계에 다시 가져온다. 진짜 아톰.

수백만 명의 움직임 디지털 트윈 데이터 → 로봇 학습 데이터. 인간의 동작 패턴을 이해하는 Physical AI는 인간과 안전하고 자연스럽게 상호작용할 수 있다.

```
디지털 트윈 데이터
  → 로봇이 인간 움직임을 예측
  → 안전한 인간-로봇 상호작용
  → 물리적 트레이너, 재활 보조, 댄스 파트너
  → 리얼 스틸의 아톰
```

---

## Phase 요약

```
Phase 1  동작 이해 엔진             ← 기술 기반
Phase 2  코칭 앱 (트랙 1 출시)      ← 사용자 + 데이터 확보
Phase 3  프리미엄 (트랙 2 출시)      ← 수익화 + VLM 부트스트래핑
Phase 4  트윈 시뮬레이션 + B2B       ← 트윈의 진짜 가치
Phase 5  도메인 확장 → 플랫폼        ← 생태계
Phase 6  Physical AI                ← 현실 세계 재투입
```

Phase 1~2가 이 프로젝트의 생사를 결정한다. 트랙 1이 충분히 쓸만한 앱이 되어야 사용자가 오고, 사용자가 와야 데이터가 쌓이고, 데이터가 쌓여야 나머지 모든 것이 가능하다.

---

## 기술 스택 진화

| | P1 | P2 | P3 | P4+ |
|--|----|----|----|----|
| 포즈 | MediaPipe | 동일 | + MMPose (다중) | 동일 |
| 트랙 1 | RF→LSTM→ST-GCN | ST-GCN (서버) | + TFLite (온디바이스) | 고도화 |
| 코칭 모델 | — | 규칙 기반 | + VLM 부트스트래핑 → 자체 모델 | 자체 모델 중심 |
| 세션 | — | 규칙 기반 | + 트윈 적응형 | + RL |
| 데이터 | Parquet | + PostgreSQL | + TimescaleDB | + 프로필 DB |
| 서버 | 로컬 | FastAPI + GCP | + GPU | 스케일링 |
| 클라이언트 | 터미널 | React Native | 동일 | + 로봇 인터페이스 |

---

*프로젝트 시작: 2026 · 관리자: Charlie*
*비전: 인간 움직임의 디지털 트윈 → Physical AI*
*전략: 트랙 1(무료)로 데이터, 트랙 2(프리미엄)로 수익, VLM→자체 모델 전환*